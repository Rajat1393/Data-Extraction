{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtabcv2Fvc/o4MrqMXjK7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajat1393/Data-Extraction/blob/main/Tokenization_and_Similaity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity and Tokenization"
      ],
      "metadata": {
        "id": "O1qUa_ywLrkG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1oZTBEOfIINq"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import en_core_web_sm"
      ],
      "metadata": {
        "id": "_hlzC2VHIbOI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "NU1fLoVJIqV1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = nlp('hello')\n",
        "w2 = nlp('hi')\n",
        "w3 = nlp('or')"
      ],
      "metadata": {
        "id": "x1_7ZJXwIgn9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1.similarity(w3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cidFeMjxI11Q",
        "outputId": "4cda5f45-c23f-4fc3-c756-28fcde26a85a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-7e00fabb65c2>:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  w1.similarity(w3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1586774408088656"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = nlp('cat dog horse person')"
      ],
      "metadata": {
        "id": "JPr-sQPFJARQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text1 in text:\n",
        "  for text2 in text:\n",
        "    print('similarity between {} and {} is {}'.format(text2,text1,text2.similarity(text1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "450eRMUIKGvt",
        "outputId": "cfa26e5a-3ce3-41ff-ba7f-1b86b17adee0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity between cat and cat is 1.0\n",
            "similarity between dog and cat is 0.5556725263595581\n",
            "similarity between horse and cat is 0.49947643280029297\n",
            "similarity between person and cat is 0.1996726244688034\n",
            "similarity between cat and dog is 0.5556725263595581\n",
            "similarity between dog and dog is 1.0\n",
            "similarity between horse and dog is 0.6669515371322632\n",
            "similarity between person and dog is 0.350044310092926\n",
            "similarity between cat and horse is 0.49947643280029297\n",
            "similarity between dog and horse is 0.6669515371322632\n",
            "similarity between horse and horse is 1.0\n",
            "similarity between person and horse is 0.28581640124320984\n",
            "similarity between cat and person is 0.1996726244688034\n",
            "similarity between dog and person is 0.350044310092926\n",
            "similarity between horse and person is 0.28581640124320984\n",
            "similarity between person and person is 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-6d6deb3f6e95>:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print('similarity between {} and {} is {}'.format(text2,text1,text2.similarity(text1)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = nlp('i am learning natural langauge processing. Course is in London. ph.d John is coming.')"
      ],
      "metadata": {
        "id": "C4bpVlW1LCDk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in text:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KukQHR1VLVeT",
        "outputId": "a628085e-2dd0-4c38-fec6-ee4aec2eb7e8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i\n",
            "am\n",
            "learning\n",
            "natural\n",
            "langauge\n",
            "processing\n",
            ".\n",
            "Course\n",
            "is\n",
            "in\n",
            "London\n",
            ".\n",
            "ph.d\n",
            "John\n",
            "is\n",
            "coming\n",
            ".\n"
          ]
        }
      ]
    }
  ]
}